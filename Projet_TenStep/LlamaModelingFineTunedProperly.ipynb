{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import llama_cpp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to D:\\downloads\\Mistral modeling\\train_data.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"D:\\downloads\\Mistral modeling\\pmbok_prompt_completion_pairs.csv\")\n",
    "\n",
    "# Define output path\n",
    "output_path = r\"D:\\downloads\\Mistral modeling\\train_data.txt\"\n",
    "\n",
    "# Format each row and write to a text file\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    for _, row in df.iterrows():\n",
    "        f.write(\"<SFT>\\n\")\n",
    "        f.write(f\"Prompt: {row['Prompt']}\\n\")\n",
    "        f.write(f\"Completion: {row['Completion']}\\n\\n\")\n",
    "\n",
    "print(f\"Data successfully written to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge graph initialized.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the knowledge graph as a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Debug message\n",
    "print(\"Knowledge graph initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF for PDF text extraction\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file.\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with fitz.open(pdf_path) as pdf:\n",
    "            for page_num in range(pdf.page_count):\n",
    "                page = pdf[page_num]\n",
    "                text += page.get_text(\"text\")\n",
    "        print(\"Successfully extracted text from PDF.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF file: {e}\")\n",
    "        text = \"\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted text from PDF.\n",
      "Activity input set successfully: Provide a detailed 7-day mobile app development plan. Outline each day’s tasks, key\n",
      "milestones, and expected deliverables.\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Input cell for activity source\n",
    "activity_input = None  # Placeholder for activity text\n",
    "pdf_path = \"D:/downloads/file.pdf\"  # Set PDF path here if using a PDF, or leave as an empty string\n",
    "\n",
    "# Full task description as text input for dynamic activity setting\n",
    "text_input = (\n",
    "    \"Provide a detailed 7-day mobile app development plan. Outline each day’s tasks, key milestones, and expected deliverables. \"\n",
    "    \"Include a brief risk assessment with potential risks and mitigation strategies. Keep responses concise and brief.\"\n",
    ")\n",
    "\n",
    "# Conditional logic to determine whether to use PDF or text input\n",
    "use_pdf = pdf_path != \"\"\n",
    "\n",
    "# Set activity_input based on whether to use PDF or text input\n",
    "if use_pdf:\n",
    "    activity_input = extract_text_from_pdf(pdf_path)\n",
    "    if not activity_input:\n",
    "        print(\"Warning: PDF text extraction failed, falling back to text input.\")\n",
    "        activity_input = text_input\n",
    "else:\n",
    "    activity_input = text_input\n",
    "\n",
    "print(\"Activity input set successfully:\", activity_input[:200] + \"...\" if len(activity_input) > 100 else activity_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gnerating Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"D:/downloads/Mistral modeling/body_of_knowledge_with_embeddings_saved.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added process 'Direct and Manage Project Work' with dependencies: [\"[['Project Management Plan'\", \"'Assignments'\", \"'Agreements'\", \"'Project Documents'\", \"'Issues'\", \"'Organizational Process Assets']]\"]\n",
      "Added process 'Monitor and Control Project Work' with dependencies: [\"[{'Attribute': 'Cost'\", \"'Value': '402500'}\", \"{'Attribute': 'Actual Cost'\", \"'Value': '402500'}\", \"{'Attribute': 'Actual Finish Date'\", \"'Value': '2017-11-27'}\", \"{'Attribute\"]\n",
      "Added process 'Identify Risks' with dependencies: ['Risks', 'Risk Owners']\n",
      "Added process 'Monitor Stakeholder Engagement' with dependencies: [\"[{'Input': 'Project Management Plan'\", \"'InputId': 1046\", \"'Output': 'Project Management Plan Update'\", \"'OutputId': 1075}\", \"{'Input': 'Project Documents'\", \"'InputId': 1054\", \"'Output': 'Project Management Plan Update\"]\n",
      "Added process 'Plan Resource Management' with dependencies: [\"[{'Outputs': 'Resource Management Plan'\", \"'Description': 'The plan that describes how the project team will acquire\", 'develop', \"and manage the organizational resources needed for the project'}\", \"{'Outputs': 'Resource Breakdown Structure'\", \"'Description': 'The hierarchy of project work to be performed and the organiz\"]\n",
      "Added process 'Plan Project Integration Management' with dependencies: ['Project Charter', 'Business documents required (e.g.', 'requirements documents', 'marketing plans', 'etc.)', 'Project management plan', 'Enterprise environmental factors', 'Organizational process assets']\n",
      "Added process 'Plan Procurements' with dependencies: [\"[{'Name': 'Contract'\", \"'Type': 'String'\", \"'MultiSelect': False\", \"'Description': 'Type of contract defined by the customer.\\\\\\\\n* Fixed-price\\\\\\\\n* Cost-reimbursable\\\\\\\\n* Time-and-materials\\\\\\\\n* Unit-price'}\", \"{'\"]\n",
      "Added process 'Risk Monitoring and Control Process' with dependencies: ['Risks']\n",
      "Added process 'Plan communications management' with dependencies: [\"[{'Quality Management Plan'\", \"'Scope Statement'\", \"'Stakeholder Register'\", \"'Project Management Plan'\", \"'Communications Management Plan'\", \"'Project Documents'\", \"'Organizational Process Assets'\", \"'Requirements Documentation'}]\"]\n",
      "Added process 'Integrate Project Work' with dependencies: [\"[{'Attribute': 'Planned Value'\", \"'Value': 12304.0}\", \"{'Attribute': 'Actual Cost'\", \"'Value': 12475.0}\", \"{'Attribute': 'Planned Value'\", \"'Value': 12204.0}\", \"{'Attribute':\"]\n",
      "Added process 'Perform Quality Assurance' with dependencies: [\"'[('Scope'\", \"'1')\", \"('Schedule'\", \"'1')\", \"('Cost'\", \"'1')\", \"('Risk'\", \"'1')]'\"]\n",
      "Added process 'Integrate Change Requests' with dependencies: [\"['Approved Change Requests'\", \"'Change Control Records'\", \"'Enterprise Environmental Factors'\", \"'Organizational Process Assets'\", \"'Project Documents'\", \"'Project Management Plan'\", \"'Project Scope Statement'\", \"'WBS Dictionary']\"]\n",
      "Added process 'Identify Risks' with dependencies: [\"[{'Name': 'Inputs'\"]\n",
      "Added process 'Identify Stakeholders' with dependencies: [\"[{'ID': 12036\", \"'Name': 'Project Documentation'}\", \"{'ID': 12038\", \"'Name': 'Project Stakeholders List'}]\"]\n",
      "Added process 'Risk Monitoring and Control' with dependencies: ['Risk assessment reports', 'Project documents updates', 'External information']\n",
      "Added process 'Direct and Manage Project Work' with dependencies: ['Activity list', \"Team members' calendars\", 'Resource calendars', 'Project documents', 'Project schedule', \"Project team's work performance information\"]\n",
      "Added process 'Direct and Manage Project Work' with dependencies: ['Work Performance Reports', 'Activity Attributes', 'Activity Costs', 'Activity Resources', 'Resource Availability']\n",
      "Added process 'Identify Risks' with dependencies: [\"['Stakeholders'\", \"'Project documentation']\"]\n",
      "Added process 'Process 2.1 Develop Project Charter' with dependencies: None\n",
      "Added process 'Define Scope' with dependencies: ['Deliverables', 'Project objectives']\n",
      "Added process 'Acquire Project Management Software' with dependencies: [\"[{'Data Type': 'Discretionary'\", \"'Element ID': '13.3.2'\", \"'Element Name': 'Software Requirement Specification'}\", \"{'Data Type': 'Discretionary'\", \"'Element ID': '13.3.4'\", \"'Element Name': 'Software\"]\n",
      "Added process 'Monitor risks' with dependencies: ['Risk report', 'Project management plan', 'Organizational process assets', 'Updates to the risk register']\n",
      "Added process 'Plan Schedule Management' with dependencies: ['Activity attributes; Activity list']\n",
      "Added process 'Control Risks' with dependencies: ['[\"Total Float\"', '\"Project Schedule\"', '\"Estimated Cost\"', '\"Actual Cost\"', '\"Estimated Time\"', '\"Actual Time\"', '\"Planned Value\"', '\"Earned Value\"', '\"Actual Cost Performance Index\"', '\"Estimate at Completion\"', '\"Estimate to Complete\"', '\"Critical Path']\n",
      "Added process 'Manage Stakeholder Engagement' with dependencies: [\"['List of Stakeholders and their needs and requirements\", 'Project Management Plan', 'Stakeholder Register', \"Work Performance Data']\"]\n",
      "Added process 'Define Scope' with dependencies: ['Requirements']\n",
      "Added process 'Control Schedule' with dependencies: ['Schedule variances', 'forecast schedule variances', 'change control procedure']\n",
      "Added process 'Direct and manage project integration' with dependencies: None\n",
      "Added process 'Time Management Plan' with dependencies: [\"[{'Name': 'Activity List'\", \"'Description': 'List of activities to be performed to produce the project deliverables.'}\", \"{'Name': 'Milestone List'\", \"'Description': 'List of milestones that define significant points in the project.'}\", \"{'Name': 'Activity Attributes'\", \"'Description': '\"]\n",
      "Added process 'Control Schedule' with dependencies: [\"[{'Description': 'Actual Duration'\", \"'Type': 'Input'}\", \"{'Description': 'Planned Value'\", \"'Type': 'Output'}]\"]\n",
      "Added process 'Plan Human Resource Management' with dependencies: ['Project manager', 'Project team members', 'Project team structure', 'Existing human resource plan']\n",
      "Added process 'Integrate Scope' with dependencies: [\"[{'Knowledge Area': 'Integration'\", \"'Process': 'Integrate Scope'\", \"'Sub-Process': ''\", \"'Outputs': 'Project deliverables'\", \"'Tools & Techniques': 'Project documents'\", \"'Input': ''}\", \"{'Knowledge Area': 'Integration'\", \"'Process': '\"]\n",
      "Added process 'Plan Procurements' with dependencies: ['Procurement Management Plan', 'Project Charter', 'Project Documents']\n",
      "Added process 'Maintain Project Procurement Documents' with dependencies: ['[4] Procurement documents', '[1] Work performance information']\n",
      "Added process 'Monitor and Control Project Time' with dependencies: ['Project Management Plan (Time)', 'Time Management Plan', 'Work Performance Data', 'Project Schedule', 'Project Team', 'Organizational Process Assets']\n",
      "Added process 'Define Scope' with dependencies: [\"[{'Description': 'Project Charter'\", \"'Name': 'Project Charter'}\", \"{'Description': 'Charter Change Log'\", \"'Name': 'Charter Change Log'}]\"]\n",
      "Added process 'Identify stakeholder requirements' with dependencies: [\"['Project documents'\", \"'Project stakeholders'\", \"'Stakeholder expectations']\"]\n",
      "Added process 'Risk Monitoring and Control' with dependencies: [\"[{'Attribute': 'Work Performance Information'\", \"'Guidance': 'During the project\", \"gather information on how project work is being performed and how well it is meeting the project requirements. This information is used to monitor and control project risks.'\", \"'InputType': 'Standard'\", \"'IsMandatory': False}\"]\n",
      "Added process 'Plan Risk Responses' with dependencies: [\"['Budget']\"]\n",
      "Added process 'Control Schedule' with dependencies: [\"[{'Category': 'Input'\", \"'Detail ID': '1'\", \"'Detail Type': 'Accounting'\", \"'Detail_Description': 'Progress Update'}\", \"{'Category': 'Input'\", \"'Detail ID': '2'\", \"'Detail Type': 'Accounting'\", \"'Detail_Description': 'Earned Value'}\", \"{'\"]\n",
      "Added process 'Plan Procurements' with dependencies: ['Procurement Management Plan']\n",
      "Added process 'Plan Scope Management' with dependencies: ['- Scope of the project']\n",
      "Added process 'Plan Procurement Management' with dependencies: ['Project Management Plan', 'Project Documents', 'Expert Judgement', 'Historical Information', 'Administrative Closure', 'Resource Calendars', 'Activity List', 'Activity Resource Requirements', 'Activity Cost Estimates', 'Procurement Documents', 'Procurement Management Plan']\n",
      "Added process 'Identify Stakeholders' with dependencies: ['Work Performance Information', 'Work Performance Reports']\n",
      "Added process 'Direct and Manage Project Work' with dependencies: [\"['actual costs'\", \"'project management plan'\", \"'project team']\"]\n",
      "Added process 'Integration management' with dependencies: [\"[{'Work Performance Data': 'Work performance data'\", \"'Project Management Plan': 'Project management plan'\", \"'Organizational Process Assets': 'Organizational process assets'\", \"'Project Documents': 'Project documents'}]\"]\n",
      "Added process 'Control Quality' with dependencies: [\"[{'Input_ID': 22\", \"'Input_Description': 'Project document updates'}]}\"]\n",
      "Added process 'Configure Integration' with dependencies: [\"[{'Description': 'Acceptance documentation from the customer'\", \"'Type': 'Input'}\", \"{'Description': 'Project documents'\", \"'Type': 'Output'}]\"]\n",
      "Added process 'Estimate Activity Resources' with dependencies: [\"['Activity'\", \"'Activity Resources'\", \"'Activity Duration']\"]\n",
      "Added process 'Plan Scope Management' with dependencies: [\"[{'Knowledge Area Name': 'Scope'\"]\n",
      "Added process 'Define Project' with dependencies: [\"[{'Value': 13\", \"'Description': 'Organizational Project Management methodology'}\", \"{'Value': 1\", \"'Description': 'Project Charter'}\", \"{'Value': 1\", \"'Description': 'Existing Enterprise Environmental Factors'}\", \"{'Value': 1\", \"'Description': 'Existing\"]\n",
      "Added process 'Execute' with dependencies: [\"[{'Description': 'Project charter'\", \"'ID': 455}\", \"{'Description': 'Organizational process assets'\", \"'ID': 619}\", \"{'Description': 'Project management plan'\", \"'ID': 488}\", \"{'Description': 'Project documents'\", \"'ID': 49\"]\n",
      "Added process 'Plan Risk Responses' with dependencies: [\"[{'Description': 'List of all risks'\", \"'ID': '140.5.1'}\", \"{'Description': 'Risk register'\", \"'ID': '140.5.2'}\", \"{'Description': 'Cost baseline'\", \"'ID': '140.5.3'}\", \"{'Description':\"]\n",
      "Added process 'Plan Project Integration Management' with dependencies: ['PMBOK Guide']\n",
      "Added process 'Define Scope' with dependencies: ['Work Breakdown Structure (WBS)', 'Project Scope Statement']\n",
      "Added process 'Perform Quantitative Risk Analysis' with dependencies: [\"[{'Input': 'Monte Carlo Simulations'\", \"'Output': 'Monte Carlo Simulations'}\", \"{'Input': 'Expected value'\", \"'Output': 'Expected value'}]\"]\n",
      "Added process 'Plan Procurements' with dependencies: ['Expert judgment', 'Project documents']\n",
      "Added process 'Direct and Manage Project Work' with dependencies: [\"[{'Work Packages': '11'}\", \"{'Project Management Plan': '11'}\", \"{'Project Team': '12'}]\"]\n",
      "Added process 'Plan Contracting' with dependencies: [\"[{'Attribute': 'Contract Type'\", \"'Input': 'Purchase Order'}\", \"{'Attribute': 'Description'\", \"'Input': 'Purchase Order for delivery of all materials'}\", \"{'Attribute': 'Estimated Cost'\", \"'Input': '285000'}]\"]\n",
      "Added process 'Manage Team' with dependencies: ['Work Performance Data', 'Performance Reports']\n",
      "Added process 'Plan Contracting' with dependencies: [\"['Plan Procurements']\"]\n",
      "Added process 'Identify Stakeholders' with dependencies: [\"[{'Named Individual or Group': 'Social Investment Specialist'}\", \"{'Named Individual or Group': 'Project Stakeholder'}\", \"{'Named Individual or Group': 'Project Sponsor'}\", \"{'Named Individual or Group': 'Project Team Member'}\", \"{'Named Individual or Group': 'Public Relations Specialist'}]\"]\n",
      "Added process 'Collect Requirements' with dependencies: ['Project scope statement', 'Project management plan', 'Stakeholder register']\n",
      "Added process 'Plan Scope Management' with dependencies: ['[2]']\n",
      "Added process 'Plan communications management' with dependencies: ['Project management plan', 'Project documents', 'Project stakeholders register']\n",
      "Added process 'Integration Management' with dependencies: [\"[{'Name': 'Project Management Plan'\", \"'Type': 'Product'}\", \"{'Name': 'Work Performance Data'\", \"'Type': 'Output'}]\"]\n",
      "Added process 'Collect Requirements' with dependencies: [\"[{'Description': 'Stakeholders'\", \"'Type': 'Output'}\", \"{'Description': 'Stakeholder engagement plan'\", \"'Type': 'Output'}\", \"{'Description': 'Project documents'\", \"'Type': 'Input'}\", \"{'Description': 'Project document updates'\", \"'Type': 'Input'}]\"]\n",
      "Added process 'Develop Project Charter' with dependencies: ['Project charter']\n",
      "Added process 'Integrate Scope with Time Management' with dependencies: ['[17] Scope Baseline', '[23] Schedule Baseline', '[3] Work Performance Data', '[4] Work Performance Information', '[19] Project Documents Update', '[20] Project Team Assignments Update']\n",
      "Added process 'Perform Quantitative Risk Analysis' with dependencies: [\"[{'Type': 'Objective'\", \"'Value': '0.75'}\", \"{'Type': 'Risk Budget'\", \"'Value': '0.65'}]\"]\n",
      "Added process 'Risk Response Planning' with dependencies: [\"['Risk Response Plan(s)'\", \"'Risk Register']\"]\n",
      "Added process 'Develop Risk Responses' with dependencies: [\"[{'ID': 2\", \"'Name': 'Risk Responses'}]\"]\n",
      "Added process 'Define scope' with dependencies: [\"[{'Category': 'Project'\", \"'Attribute': 'Name'\", \"'Value': 'NewCarProject'}\", \"{'Category': 'Project'\", \"'Attribute': 'OwnerID'\", \"'Value': 'A0007'}\", \"{'Category': 'Project'\", \"'Attribute': 'CustomerID'\", \"'Value': 'B00\"]\n",
      "Added process 'Close Procurements' with dependencies: [\"['CC'\", \"'CP'\", \"'PS'\", \"'PR'\", \"'PM'\", \"'MS'\", \"'PS'\", \"'PO'\", \"'PM'\", \"'Vendor']\"]\n",
      "Added process 'Develop Project Team' with dependencies: [\"['Project team'\", \"'Project stakeholders'\", \"'Project manager']\"]\n",
      "Added process 'Control Integration' with dependencies: [\"[{'Activity ID': '112.0.1'\", \"'Activity Name': 'Monitor Performance of Integration'\", \"'Activity Type': 'Output'\", \"'Activity Description': 'Monitor the performance of project integration and make necessary changes to its execution.'}\", \"{'Activity ID': '112.0.2\"]\n",
      "Added process 'Manage Stakeholder Expectations' with dependencies: ['Project management plan', 'risks register', 'risk management plan']\n",
      "Added process 'Monitor and Control Project Work' with dependencies: [\"[{'Attribute': 'Project Management Plan'\", \"'Guidance': 'The Project Management Plan is the document that describes how the project will be executed\", \"monitored and controlled.'\", \"'Input': 'Project Management Plan'}\", \"{'Attribute': 'Work Performance Data'\", \"'Guidance': 'The data collected on the project as\"]\n",
      "Added process 'Manage changes' with dependencies: [\"[{'Attribute': 'Change Requests'\", \"'Guidance': ''\", \"'InputType': 'Text'\", \"'IsMandatory': False\", \"'Length': ''\", \"'Name': 'Change Requests'\", \"'Order': 1}\", \"{'Attribute': 'WBS Dictionary'\", \"'Guidance': ''\", \"'InputType':\"]\n",
      "Added process 'Direct and Manage Project Work' with dependencies: ['Planned Value', 'Earned Value', 'Actual Cost', 'Resource Requirements', 'Work Performance Information', 'Work Performance Data', 'Performance Measurement Baseline']\n",
      "Added process 'Plan Procurements' with dependencies: ['Procurement Management Plan']\n",
      "Added process 'Plan Purchase Requisitions' with dependencies: [\"[{'Attribute': 'Project Documentation'\", \"'Values': ['Project Charter']}\", \"{'Attribute': 'Business Case'\", \"'Values': ['Business Case']}\", \"{'Attribute': 'Scope Statement'\", \"'Values': ['Detail Requirements']}]\"]\n",
      "Added process 'Manage Project Team' with dependencies: [\"[{'Name': 'Project Charter'\", \"'Description': 'Charter that defines the project and its objectives.'}\", \"{'Name': 'Plan Human Resource Management'\", \"'Description': 'Plan for the acquisition and management of resources needed for the project.'}\", \"{'Name': 'Resource Calendars'\", \"'Description': '\"]\n",
      "Added process 'Estimate Activity Durations' with dependencies: ['Assumptions about the activity durations', 'Activity list', 'Resource requirements']\n",
      "Added process 'Direct and Manage Project Work' with dependencies: [\"['Activity List'\", \"'Activity Attributes'\", \"'Activity Cost Estimates'\", \"'Activity Dependencies'\", \"'Activity Resource Requirements'\", \"'Activity Schedule'\", \"'Project Schedule'\", \"'Resource Calendars'\", \"'Resource Cost Estimates'\", \"'Resource Availability'\", \"'Resource Project Assignments'\", \"'Resource\"]\n",
      "Added process 'Plan Cost Management' with dependencies: ['Scope Statement']\n",
      "Added process 'Plan Procurement Management' with dependencies: ['Procurement Documents']\n",
      "Added process 'Monitor Risks' with dependencies: ['Work Performance Reports', 'Risk Log']\n",
      "Added process 'Plan Procurements' with dependencies: ['Strategic procurement plan', 'Procurement management plan', 'List of potential sellers', 'Project documents updates', 'Contracts', 'List of approved sellers', 'Legal documents', 'List of potential sellers', 'Procurement management plan']\n",
      "Added process 'Monitor and Control Project Work' with dependencies: [\"[{'Attribute': 'Project Management Plan'\", \"'Guidance': ''\", \"'Input': 'Yes'}\", \"{'Attribute': 'Project Documents'\", \"'Guidance': ''\", \"'Input': 'Yes'}\", \"{'Attribute': 'Work Performance Data'\", \"'Guidance': ''\", \"'Input': 'Yes'}\", \"{'Attribute': 'Work Performance\"]\n",
      "Added process 'Manage Project Knowledge' with dependencies: ['Project Management Information System (PMIS)', 'Lessons learned']\n",
      "Added process 'Direct and Manage Project Work' with dependencies: ['Work to be performed', 'Boundary conditions', 'Project management plan', 'Work performance information']\n",
      "Added process 'Develop project charter' with dependencies: [\"['Organizational process assets'\", \"'Project charter'\", \"'Project manager'\", \"'Stakeholder register'\", \"'Scope management plan']\"]\n",
      "Added process 'Stakeholder Engagement' with dependencies: [\"[{'Description': 'Stakeholder'\", \"'Type': 'Output'}\", \"{'Description': 'Meeting'\", \"'Type': 'Tool & Technique'}]\"]\n",
      "Added process 'Implement Arrange Resources' with dependencies: [\"[{'Attribute': 'Resource'\", \"'Guidance': 'The actual resource that is assigned to the work'\", \"'InputType': 'User'\", \"'UseDefault': False\", \"'UseDefaultValue': False\", \"'Value': ''}]\"]\n",
      "Added process 'Analyze Schedule' with dependencies: [\"[{'Parameter_ID': 115\", \"'Parameter_Name': 'Schedule'}]\"]\n",
      "Added process 'Identify Risks' with dependencies: None\n",
      "Added process 'Plan Procurements' with dependencies: [\"[{'Parameter': 'Procurement Management Plan'\", \"'Type': 'Output'}\", \"{'Parameter': 'Procurement Management Plan'\", \"'Type': 'Output'}]\"]\n",
      "Added process 'Collect Requirements' with dependencies: ['Project charter', 'Scope Statement']\n",
      "Added process 'Define Scope' with dependencies: [\"[{'Name': 'Deliverables'\", \"'Type': 'Output'\", \"'Multiples': False\", \"'Description': 'Identified deliverables '}\", \"{'Name': 'Product Scope Statement'\", \"'Type': 'Output'\", \"'Multiples': False\", \"'Description': 'Product scope statement '}\", \"{'Name':\"]\n",
      "Added process 'Direct and Manage Project Work' with dependencies: [\"['work performance data'\", \"'work performance information'\", \"'work performance reports']\"]\n",
      "Added process 'Develop Project Charter' with dependencies: ['Organizational process assets', 'Enterprise environmental factors']\n",
      "Added process 'Define Project' with dependencies: None\n",
      "Added process 'Scope Planning' with dependencies: ['Scope Statement']\n",
      "Added process 'Monitor Risks' with dependencies: [\"[{'Key Inputs': 'Risks'}\", \"{'Key Outputs': 'Risk Register'}]\"]\n",
      "Added process 'Define Scope' with dependencies: ['Deliverable list', 'Stakeholder register']\n",
      "Added process 'Plan Communications Management' with dependencies: [\"[{'Attribute': 'Communications Management Plan'\", \"'Guidance': 'The Communications Management Plan is created during this process. It provides direction for the development and implementation of the communications approach and contains the communications requirements and the communications management plan.'\", \"'InputType': 'Document Output'}\", \"{'Attribute': 'Organizational\"]\n",
      "Added process 'Plan Human Resource Management' with dependencies: ['[28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43']\n",
      "Added process 'Plan Procurements' with dependencies: ['Agreements', 'Planning information', 'Procurement documents', 'Procurement management plan', 'Procurement register']\n",
      "Added process 'Risk Monitoring and Control' with dependencies: ['Work Performance Reports', 'Performance Reports', 'Change Requests', 'Project Management Plan', 'Organizational Process Assets', 'Process Improvement Plan', 'Risk Register', 'Risk Log', 'Expert Judgement', 'Meetings', 'Risk Management Plan', 'Contracts', 'Project Documents', 'Work Performance Information', 'Assum']\n",
      "Added process 'Manage Quality' with dependencies: [\"[{'Description': 'Quality metrics'\", \"'IsOutput': False\", \"'IsControl': False\", \"'IsInput': True\", \"'AttributeID': 6143}\", \"{'Description': 'Project plan'\", \"'IsOutput': False\", \"'IsControl': False\", \"'IsInput': True\", \"'Attribute\"]\n",
      "Added process 'Perform Integration' with dependencies: ['Project Management Plan', 'Integration Management Plan', 'Integrated change request', 'Acceptance criteria', 'Deliverables']\n",
      "Added process 'Conduct Procurements' with dependencies: ['Contracts', 'Contract status']\n",
      "Added process 'Integrate the Project Work' with dependencies: [\"[{'ID': 18\", \"'Description': 'Project Integration Management Plan'}\", \"{'ID': 6\", \"'Description': 'Project Management Plan'}\", \"{'ID': 17\", \"'Description': 'Project Integration Management Documents'}]\"]\n",
      "Added process 'Perform Qualitative Risk Analysis' with dependencies: ['[15', '16', '17', '18', '19', '20]']\n",
      "Added process 'Control Costs' with dependencies: [\"[{'Attribute': 'Cost Management Plan'\", \"'Attribute_ID': 8\", \"'Guidance': 'Tools and techniques: Expert judgment\", 'Meetings', \"Performance reviews'\", \"'Input': 'T'\", \"'Input_Description': 'T'}\", \"{'Attribute': 'Project Management Plan'\", \"'Attribute_ID':\"]\n",
      "Added process 'Plan Procurements' with dependencies: [\"[{'Attribute': 'Project Management Plan'\", \"'Attribute_ID': 167}\", \"{'Attribute': 'Project Management Plan Updates'\", \"'Attribute_ID': 168}\", \"{'Attribute': 'Organizational Process Assets'\", \"'Attribute_ID': 169}\", \"{'Attribute': '\"]\n",
      "Added process 'Develop Project Schedule' with dependencies: ['Schedule Management Plan\\\\Project Management Plan']\n",
      "Added process 'Execute Project Integration Management Plan' with dependencies: [\"[{'Name': 'Project Documentation'\", \"'IsOutput': False\", \"'IsInput': True\", \"'MultiSelect': False\", \"'Description': 'Project documentation'\", \"'AttributeID': 1528}\", \"{'Name': 'Project Management Plan'\", \"'IsOutput': False\", \"'IsInput': True\"]\n",
      "Added process 'Plan Procurements' with dependencies: ['Product scope', 'Stakeholders']\n",
      "Added process 'Direct and Manage Project Work' with dependencies: [\"[{'Input': 'Scope Baseline'}\", \"{'Input': 'Work Performance Data'}\", \"{'Input': 'Project Documents'}]\"]\n",
      "Added process 'Plan Communications' with dependencies: ['[7] Communications Management Plan', '[8] Organizational Process Assets', '[9] Project Documents']\n",
      "Added process 'Integrate Project Work' with dependencies: ['Work Performance Information', 'Change Requests', 'Project Management Plan Update', 'Deliverables']\n",
      "Added process 'Estimate Cost of Risks' with dependencies: [\"[{'Attribute': 'Cost estimating techniques and data'\", \"'Guidance': 'Use the cost estimating techniques and data in the risk register\", 'the risk management plan', \"and the project management plan to estimate the cost of risks'\", \"'Input': 'Risk register\", 'risk management plan', \"project management plan'}]\"]\n",
      "Added process 'Plan Risk Management' with dependencies: ['Work Breakdown Structure', 'Risk Management Plan', 'Cost Baseline']\n",
      "Added process 'Define Scope' with dependencies: ['Deliverables']\n",
      "Added process 'Perform Integration' with dependencies: [\"[{'Activity ID': '48'\", \"'Activity Name': 'Integration Schedule'\", \"'Task ID': '48'\", \"'Task Name': 'Integration Schedule'\", \"'Successor Activity ID': '49'\", \"'Successor Activity Name': 'Integration Cost Budgeting'\", \"'Lag': '\"]\n",
      "Added process 'Conduct Probability and Impact Analysis' with dependencies: ['Key inputs required for the process: Risk Management Plan', 'Risk Register', 'Risk Probability', 'Risk Impact', 'Project Schedule', 'Risk Data Quality']\n",
      "Added process 'Determine Key Stakeholders' with dependencies: [\"[{'Type': 'SS'\", \"'Description': 'Stakeholder information'}\", \"{'Type': 'SS'\", \"'Description': 'Stakeholder influence'}\", \"{'Type': 'SS'\", \"'Description': 'Stakeholder interest'}]\"]\n",
      "Added process 'Develop Project Charter' with dependencies: [\"['Project Charter'\", \"'Stakeholders']\"]\n",
      "Added process 'Monitor and control risks' with dependencies: [\"[['Process inputs'\", \"'Project management plan'\", \"'Risk register'\", \"'Work performance information'\", \"'Project documents updates']]\"]\n",
      "Added process 'Plan Procurement Management' with dependencies: ['[{']\n",
      "Added process 'Plan Schedule Management' with dependencies: [\"[{'Activity Attributes': 'Activity attributes (this is a non-project activity)'\", \"'Activity ID': '35'\", \"'Activity Name': 'Review of the current project schedule'}\", \"{'Activity Attributes': 'Activity attributes (this is a project activity)'\", \"'Activity ID': '134'\", \"'Activity\"]\n",
      "Added process 'Direct and Manage Project Work' with dependencies: [\"['Project Work Schedule'\", \"'Project Team Members'\", \"'Project Stakeholders'\", \"'Project Work Performance Reports'\", \"'Project Work Progress'\", \"'Project Work Performance'\", \"'Project Issues List'\", \"'Project Work Forecast'\", \"'Project Work']\"]\n",
      "Added process 'Integrate Scope' with dependencies: [\"[{'Description': 'Updated project documents\", 'including the scope baseline', \"after performing Integrate Scope.'\", \"'Id': 15\", \"'Type': 'Product'\", \"'Usage': 'O'}\", \"{'Description': 'Updated project management plan\", 'including the scope baseline', \"after performing Integrate Scope.'\", \"'Id':\"]\n",
      "Added process 'Direct and Manage Project Work' with dependencies: ['Activity list', 'Activity attributes', 'Resource requirements']\n",
      "Added process 'Develop Project Charter' with dependencies: ['Project sponsor', 'Stakeholders', 'Project objectives']\n",
      "Added process 'Control Scope' with dependencies: [\"[{'Name': 'Work Performance Information'\", \"'Type': 'Product'}\", \"{'Name': 'Scope Change Requests'\", \"'Type': 'Product'}]\"]\n",
      "Added process 'Plan Project Integration Management' with dependencies: ['List of all project management processes', 'List of all project documents', 'List of all project team members']\n",
      "Added process 'Identify Risks' with dependencies: [\"['Risk register'\", \"'Risk report']\"]\n",
      "Added process 'Plan Integration Management' with dependencies: ['Project management plan', 'project documents']\n",
      "Added process 'Develop Project Charter' with dependencies: ['Business documents required to be developed']\n",
      "Added process 'Identify Risk' with dependencies: [\"[{'Identified Risks': 'Unavailability of Project Sponsor'}]\"]\n",
      "Added process 'Direct and Manage Project Work' with dependencies: [\"[{'Input': 'Requirements documentation'\", \"'Output': 'Work performance information'}\", \"{'Input': 'Work performance information'\", \"'Output': 'Decisions'}]\"]\n",
      "Added process 'Monitor and Control Project Work' with dependencies: [\"['Project Management Plan'\", \"'Project Documents'\", \"'Project Work Performance Reports'\", \"'Change Requests'\", \"'Scheduled Baseline'\", \"'Actual Costs'\", \"'Project Cost Management Plan']\"]\n",
      "Added process 'Contract Administer' with dependencies: [\"[{'Name': 'Change Request'\", \"'Type': 'Input'}\", \"{'Name': 'Performance Report(s)'\", \"'Type': 'Input'}\", \"{'Name': 'Drift Identification Techniques'\", \"'Type': 'Tool & Technique'}]\"]\n",
      "Added process 'Procurement Planning' with dependencies: [\"[{'key': 'PMP Procurement Management Plan'\", \"'type': 'STANDARD'}\", \"{'key': 'Project documents'\", \"'type': 'STANDARD'}\", \"{'key': 'Proposals'\", \"'type': 'STANDARD'}]\"]\n",
      "Added process 'Manage Project Knowledge' with dependencies: ['Documents', 'Lessons Learned Register']\n",
      "Added process 'Acquire Project Stakeholder Support' with dependencies: ['Stakeholder Register']\n",
      "Added process 'Plan Procurements' with dependencies: ['Procurement Management Plan']\n",
      "Added process 'Monitor and Control Project Work' with dependencies: [\"['Project Scope Statement'\", \"'Scope Baselines'\", \"'Work Performance Data'\", \"'Project Management Plan'\", \"'Requirements Management Plan']\"]\n",
      "Added process 'Define Scope' with dependencies: [\"[{'Attribute_Name': 'Project Scope Statement'\", \"'Attribute_ID': 1791}\", \"{'Attribute_Name': 'Project Charter'\", \"'Attribute_ID': 1790}\", \"{'Attribute_Name': 'Stakeholder Register'\", \"'Attribute_ID': 179\"]\n",
      "Added process 'Estimate Activity Durations' with dependencies: ['resources', 'cost estimates', 'activity definition', 'activity attributes']\n",
      "Added process 'Plan Procurements' with dependencies: ['Project management plan', 'stakeholder register', 'enterprise environmental factors', 'organizational process assets', 'project procurement management plan']\n",
      "Added process 'Close Project or Phase' with dependencies: [\"[{'Actor': 'Project Manager'\", \"'Verb': 'Distribute'\", \"'Noun': 'Lessons Learned Report'\", \"'Object': 'Outside Demanding Client'}\", \"{'Actor': 'Project Manager'\", \"'Verb': 'Distribute'\", \"'Noun': 'Lessons Learned Report'\"]\n",
      "Added process 'Risk Register Update' with dependencies: ['[9] Risk Register']\n",
      "Added process 'Direct and Manage Project Knowledge' with dependencies: ['Enterprise environmental factors', 'Organizational process assets', 'Organizational knowledge']\n",
      "Added process 'Perform Qualitative Risk Analysis' with dependencies: ['Risk register']\n",
      "Added process 'Plan Contracting' with dependencies: [\"[{'Activity_Attributes': {'Activity_ID': 13\", \"'Activity_Code': '51.4'\", \"'Activity_Description': 'Determine procurement strategy'}}]\"]\n",
      "Added process 'Identify Stakeholders' with dependencies: [\"[{'Name': 'Product Description'\", \"'Type': 'Input'\", \"'MultiSelect': False\", \"'Description': 'Description of the product\", 'service', \"or result'}]\"]\n",
      "Added process 'Direct and manage project integration' with dependencies: [\"[{'Name': 'Project Management Plan'\", \"'ID': 512}\", \"{'Name': 'Project Integration Management Plan'\", \"'ID': 535}\", \"{'Name': 'Project Team'\", \"'ID': 654}\", \"{'Name': 'Project Stakeholders'\", \"'ID': 6\"]\n",
      "Added process 'Develop Project Charter' with dependencies: [\"['Business need'\", \"'Project Management Plan'\", \"'Project charter'\", \"'Project management plan'\", \"'Project sponsor'\", \"'Project stakeholders']\"]\n",
      "Added process 'Plan Project Integration Management' with dependencies: ['Scope baseline', 'Cost baseline', 'Schedule baseline', 'Resource breakdown structure']\n",
      "Added process 'Collect Requirements' with dependencies: [\"[{'Description': 'Product Description'\", \"'Type': 'SS'}\", \"{'Description': 'Product Performance Specification'\", \"'Type': 'SS'}\", \"{'Description': 'Product Standards'\", \"'Type': 'SS'}\", \"{'Description': 'Project Documents'\", \"'Type': 'SS'}]\"]\n",
      "Added process 'Identify Stakeholders' with dependencies: [\"[{'Key Input': 'Organizational Process Assets'\", \"'Description': 'Organizational process assets used to perform the process.'\", \"'IsOutput': False}\", \"{'Key Input': 'Project Charter'\", \"'Description': 'Project charter containing project objectives\", 'deliverables', 'risks', 'assumptions', 'constraints', 'and']\n",
      "Added process 'Define Scope' with dependencies: ['Solution scope']\n",
      "Added process 'Perform Quantitative Risk Analysis' with dependencies: ['Risk register', 'Project documents']\n",
      "Added process 'Quality Control' with dependencies: ['Outputs', 'Work performance data']\n",
      "Added process 'Identify Stakeholders' with dependencies: [\"[{'Name': 'Project Documents'\", \"'Type': 'Input'}\", \"{'Name': 'Project Manager'\", \"'Type': 'Input'}]\"]\n",
      "Added process 'Identify Stakeholders' with dependencies: ['List of stakeholders and their interests']\n",
      "Added process 'Perform Integration' with dependencies: ['Project documents', 'Project deliverables', 'Project team']\n",
      "Added process 'Direct and Manage Project Work' with dependencies: [\"[{'Name': 'Work Performance Information'\", \"'Type': 'Input'\", \"'Multiplicity': 'Mandatory'\", \"'Multiplicity_Definition': 'For each work package.'}\", \"{'Name': 'Performance Reports'\", \"'Type': 'Input'\", \"'Multiplicity': 'Mandatory'\", \"'Multiplicity\"]\n",
      "Added process 'Monitor and Control Project Work' with dependencies: [\"[{'Activity ID': 1\", \"'Activity Name': 'Licensing and Permitting'\", \"'Activity Type': 'Finish To Start'\", \"'Duration': 1}\", \"{'Activity ID': 2\", \"'Activity Name': 'Licensing and Permitting'\", \"'Activity Type': 'Finish To Start\"]\n",
      "Added process 'Conduct Procurements' with dependencies: [\"[{'Input': 'Project Management Plan'}\", \"{'Input': 'Procurement Management Plan'}\", \"{'Input': 'Project documents'}\", \"{'Input': 'Acceptable Quality Level (AQL)'}\", \"{'Input': 'Quality Control Limit (QCL)'}\", \"{'Input': 'Quality Assurance Limit (\"]\n",
      "Added process 'Manage Project Team' with dependencies: [\"[{'Name': 'Team Members'\", \"'Type': 'Resource'}]\"]\n",
      "Added process 'Develop Project Charter' with dependencies: ['Project Charter', 'Stakeholders', 'Organizational Process Assets', 'Enterprise Environmental Factors']\n",
      "Added process 'Manage Project Knowledge' with dependencies: [\"[{'ID': 115\", \"'Name': 'Conduct Integrated Change Control'}]\"]\n",
      "Added process 'Plan Procurement Management' with dependencies: [\"[{'Name': 'Lawyer'\", \"'Type': 'Resource'}]\"]\n",
      "Added process 'Develop Team' with dependencies: [\"['Roles and responsibilities for the project']\"]\n",
      "Added process 'Direct and Manage Project Work' with dependencies: ['Work Performance Reports', 'Work Performance Information']\n",
      "Added process 'Define scope' with dependencies: [\"[{'Description': 'Approved customer requirements documented in the project scope statement'\", \"'ID': 267\", \"'Type': 'Input'}]\"]\n",
      "Added process 'Close Procurements' with dependencies: ['Procurement documents']\n",
      "Added process 'Plan Procurements' with dependencies: [\"[{'Description': 'Procurement requirements'\", \"'ID': 125}\", \"{'Description': 'Procurement management plan'\", \"'ID': 518}\", \"{'Description': 'Procurement documents'\", \"'ID': 126}\", \"{'Description': 'Vendor solicitation packages'\"]\n",
      "Added process 'Collect Requirements' with dependencies: ['Requirements documents']\n",
      "Added process 'Plan Risk Responses' with dependencies: [\"[{'Input': 'Risk Trigger'\", \"'Type': 'Text'\", \"'IsLookup': False\", \"'IsOutput': False\", \"'LookupName': 'NA'\", \"'LookupAlias': 'NA'\", \"'TableName': 'NA'\", \"'SourceColumn': 'NA'\", \"'RelatedTable': 'NA'}\"]\n",
      "Added process 'Plan Risk Responses' with dependencies: ['Risk Register']\n",
      "Added process 'Scope verification' with dependencies: [\"[{'Attribute': 'Scope Statement'\", \"'Guidance': ''\", \"'Input': 'The project scope statement'}\", \"{'Attribute': 'WBS'\", \"'Guidance': ''\", \"'Input': 'The project WBS'}\", \"{'Attribute': 'Deliverables'\", \"'Guidance': ''\", \"'Input': 'The project deliverables\"]\n",
      "Added process 'Direct and Manage Project Work' with dependencies: ['Work performance report', 'Work performance data', 'Work performance information']\n",
      "Added process 'Identify Stakeholders' with dependencies: [\"['Identify Stakeholders'\", \"'Stakeholder Name'\", \"'Stakeholder Information'\", \"'Stakeholder Role']\"]\n",
      "Added process 'Manage Project Knowledge' with dependencies: [\"[{'Knowledge Area': 'Integration Management'\", \"'Process': 'Manage Project Knowledge'\", \"'Input': 'Knowledge from previous projects'}\", \"{'Knowledge Area': 'Integration Management'\", \"'Process': 'Manage Project Knowledge'\", \"'Input': 'Project Charter'}\", \"{'K\"]\n",
      "Added process 'Plan Human Resource Activities' with dependencies: ['Project documents', 'Enterprise environmental factors', 'Organizational process assets']\n",
      "Added process 'Conduct Procurements' with dependencies: [\"[{'Attribute': 'Organizational Process Assets'\", \"'Guidance': 'Project records\", 'including formal documents and approved changes', 'lessons learned', \"and historical information'\", \"'InputType': 'document'}\", \"{'Attribute': 'Project Management Plan'\", \"'Guidance': 'Approved project management plan'\", \"'InputType':\"]\n",
      "Added process 'Develop Project Charter' with dependencies: ['Business needs', 'Business case', 'Stakeholder identification', 'Project charter approval', 'Project manager selection', 'Project scope statement']\n",
      "Added process 'Plan Procurements' with dependencies: ['Scope baseline', 'time schedule', 'activity list', 'resource calendars', 'risk register', 'assumptions log', 'procurement documents (contracts', 'RFPs', 'RFIs', 'contracts)', 'WBS dictionary', 'project management plan', 'stakeholder register']\n",
      "Added process 'Manage Stakeholder Expectations' with dependencies: ['Work Performance Reports']\n",
      "Added process 'Manage project integration' with dependencies: ['[{']\n",
      "Added process 'Monitor and Control Project Work' with dependencies: [\"['Target cost at completion (CAC)'\", \"'Actual cost of work performed (ACWP)'\", \"'Budget at completion (BAC)'\", \"'Earned value (EV)'\", \"'Planned value (SV)'\", \"'Remaining budget at completion (BAC-EV)'\", \"'Percent complete'\", \"'Estimate at\"]\n",
      "Added process 'Manage stakeholder engagement' with dependencies: ['Stakeholder engagement plan', 'Stakeholder register', 'Stakeholder engagement records', 'Performance reports']\n",
      "Added process 'Estimate Activity Durations' with dependencies: ['resources required to complete activities']\n",
      "Added process 'Identify Human Resource Requirements' with dependencies: ['Work products; Assumptions; Constraints']\n",
      "Added process 'Plan Procurement Management' with dependencies: ['Procurement Management Plan', 'Procurement Documents', 'List of Potential Suppliers', 'Procurement Strategy', 'Procurement Solicitation Documents']\n",
      "Added process 'Identify risk' with dependencies: ['Identified risks', 'Risk categories', 'Matching criteria', 'Risk responses']\n",
      "Added process 'Plan Procurements' with dependencies: [\"[{'Dimension': 'Time'\", \"'Measure': 'Days'}\", \"{'Dimension': 'Cost'\", \"'Measure': 'Cost'}]\"]\n",
      "Added process 'Plan Schedule Management' with dependencies: ['[4', '5', '6', '7]']\n",
      "Added process 'Direct and Manage Project Knowledge' with dependencies: [\"[{'Description': 'Project management tools'\", \"'Type': 'Output'}\", \"{'Description': 'Project data'\", \"'Type': 'Input'}\", \"{'Description': 'Project management plan'\", \"'Type': 'Input'}]\"]\n",
      "Added process 'Make or buy decision' with dependencies: [\"[{'Attribute': 'Organizational Process Assets'\", \"'Value': 'Organizational Process Assets'}\", \"{'Attribute': 'Project Management Plan'\", \"'Value': 'Project Management Plan'}\", \"{'Attribute': 'Organizational Process Assets'\", \"'Value': 'Organizational Process Assets'}]\"]\n",
      "Added process 'Manage Stakeholder Engagement' with dependencies: [\"[{'Attribute_Name': 'Stakeholder'\", \"'Attribute_Value': 'Stakeholder 1'}\", \"{'Attribute_Name': 'Stakeholder'\", \"'Attribute_Value': 'Stakeholder 2'}]\"]\n",
      "Added process 'Plan Procurement Management' with dependencies: [\"[{'Key Input': 'Project Management Plan'\", \"'Description': 'Scheduling tools and techniques\", 'Procurement management knowledge areas', \"and project management information systems'}\", \"{'Key Input': 'Organization Process Assets'\", \"'Description': 'Enterprise environmental factors\", 'Organizational process assets', 'and historical information']\n",
      "Added process 'Plan Procurements' with dependencies: [\"[{'Attribute': 'Project Management Plan'\", \"'Guidance': 'The project management plan for the project or project phase that is being planned.'\", \"'InputType': 'Document Output'}\", \"{'Attribute': 'Project Documents'\", \"'Guidance': 'The documents and information that are relevant to the project.'\", \"'InputType\"]\n",
      "Added process 'Perform Quality Control' with dependencies: [\"['Scope Statement'\", \"'WBS'\", \"'Accepted Deliverables'\", \"'Quality Metrics'\", \"'WBS Dictionary']\"]\n",
      "Added process 'Identify Stakeholders' with dependencies: [\"[{'Type': 'T'\", \"'Name': 'Stakeholder Register'\", \"'ID': '11.1.5'}\", \"{'Type': 'T'\", \"'Name': 'Stakeholder Engagement Plans'\", \"'ID': '11.1.6'}\", \"{'Type': 'T'\", \"'Name\"]\n",
      "Added process 'Close Procurement Contracts' with dependencies: [\"[{'Attribute': 'Close Procurement Contracts'\", \"'Guidance': 'None'\", \"'Input': 'No input is required for this process.'}\", \"{'Attribute': 'Seller'\", \"'Guidance': 'None'\", \"'Input': 'None'}]\"]\n",
      "Added process 'Plan procurement management' with dependencies: [\"[{'Attribute': 'Procurement Management Plan'\", \"'Attribute_ID': 183\", \"'Attribute_Description': 'Plan that describes the activities required to buy goods and services\", \"as well as the methods and criteria to be used.'}\", \"{'Attribute': 'Contracts'\", \"'Attribute_ID':\"]\n",
      "Added process 'Plan Project Integration Management' with dependencies: [\"[{'ID': 1\", \"'Name': 'Organization Process Assets'\", \"'Type': 'Input'\", \"'Multiplicity': '0..1'}\", \"{'ID': 2\", \"'Name': 'Project Charter'\", \"'Type': 'Input'\", \"'Multiplicity': '1..1'}\", \"{'\"]\n",
      "Added process 'Direct and Manage Project Work' with dependencies: ['Work Performance Data', 'Project Documents']\n",
      "Added process 'Direct and Manage Project Execution' with dependencies: [\"[{'Activity List'\", \"'Activity Attributes'\", \"'Resource Requirements'\", \"'Project Document Updates'\", \"'Project Schedule'\", \"'Project Costs'}]\"]\n",
      "Added process 'Develop Risk Responses' with dependencies: [\"[{'Risk_Category': 'Financial'\", \"'Risk_ID': 'RISK002'\", \"'Risk_Description': 'We will not be able to fulfill our contractual obligations.'}]\"]\n",
      "Added process 'Schedule Risk Analysis' with dependencies: [\"[{'Input': 'Work Breakdown Structure'\"]\n",
      "Added process 'Direct and Manage Project Execution' with dependencies: [\"['Organizational process assets'\", \"'Project management plan'\", \"'Team']\"]\n",
      "Added process 'Direct and Manage Project Work' with dependencies: [\"['Work performance data'\", \"'Work performance information'\", \"'Team performance reports']\"]\n",
      "Added process 'Risk Monitoring and Control' with dependencies: ['[64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79']\n",
      "Added process 'Plan Risk Responses' with dependencies: [\"[{'Attribute': 'Assumptions Log'\", \"'Guidance': 'The assumptions log is a project document that provides a record of the project team\\\\'s documented assumptions and the underlying reasons for them. The team is responsible for keeping the list updated.'\", \"'Input': 'No'}]\"]\n",
      "Added process 'Estimate Activity Resources' with dependencies: [\"['Activity/WBS ID'\", \"'Activity/WBS Name'\", \"'Activity Description'\", \"'Activity Type'\", \"'Activity Cost Code'\", \"'Activity Duration'\", \"'Activity Sequence'\", \"'Activity Resource Requirements'\", \"'Activity Resource Requirements'\", \"'Activity Resource Requirements']\"]\n",
      "Added process 'Gather Requirements' with dependencies: [\"[{'Attribute': 'Product Scope'\", \"'Attribute_ID': 370\", \"'Attribute_Name': 'Product Scope'\", \"'Data_Type': 'Text'\", \"'Description': 'A product scope statement is a description of the product or service the project is to develop or acquire.'\", \"'Is_\"]\n",
      "Added process 'Collect Requirements' with dependencies: [\"[{'Description': 'Requirements Document'\", \"'IsOutput': False\", \"'IsInput': True\", \"'Multiplicity': '1..*'}\", \"{'Description': 'Project Management Plan'\", \"'IsOutput': False\", \"'IsInput': True\", \"'Multiplicity': '1..*'}\", \"{'Description': 'Organ\"]\n",
      "Added process 'Integrate' with dependencies: [\"['WBS Output'\", \"'Work Performance Information'\", \"'Change Request'\", \"'Scope Baseline']\"]\n",
      "Added process 'Risk Planning' with dependencies: ['Risk categories']\n",
      "Added process 'Define Scope' with dependencies: ['Scope Statement', 'Project Charter']\n",
      "Added process 'Integration Planning' with dependencies: [\"[{'Name': 'Time'\", \"'Value': 0.0}\", \"{'Name': 'Cost'\", \"'Value': 0.0}]\"]\n",
      "Added process 'Integration management' with dependencies: [\"[{'Attribute': 'Project closure report'\", \"'Type': 'Output'}\", \"{'Attribute': 'Change requests'\", \"'Type': 'Output'}\", \"{'Attribute': 'Project documents updates'\", \"'Type': 'Output'}\", \"{'Attribute': 'Project file'\", \"'Type': 'Output'}\", \"{'Attribute': 'Closed project or phase\"]\n",
      "Added process 'Identifying Costs' with dependencies: ['Cost Management Plan', 'Scope Baseline', 'Schedule Baseline', 'Resource Calendars']\n",
      "Added process 'Plan stakeholder management' with dependencies: ['Work Breakdown Structure', 'Cost Baseline', 'Cost Management Plan', 'Organizational Process Assets', 'Project Charter']\n",
      "Added process 'Collect Requirements' with dependencies: [\"[{'ActivityAttributes': 'None'\"]\n",
      "Added process 'Plan Procurements' with dependencies: [\"[{'Description': 'Approved Budget'\", \"'Type': 'Input'}\", \"{'Description': 'Approved Quality Standards'\", \"'Type': 'Input'}\", \"{'Description': 'Organizational Process Assets'\", \"'Type': 'Input'}\", \"{'Description': 'Organizational Process Assets'\", \"'Type': '\"]\n",
      "Added process 'Plan Procurements' with dependencies: ['Project Requirements Document']\n",
      "Added process 'Plan Project Integration Management' with dependencies: [\"['Integration activities'\", \"'Procurement management plan'\", \"'Stakeholder register'\", \"'Scope baseline'\", \"'Schedule baseline'\", \"'Cost baseline']\"]\n",
      "Added process 'Create WBS' with dependencies: [\"[{'Attribute': 'Project Documents'\", \"'Guidance': 'Include project documents\", 'like the project charter', 'project management plan', 'requirements documentation', \"etc.'\", \"'Input': 'No'}]\"]\n",
      "Added process 'Conduct Procurements' with dependencies: [\"[{'Attribute': 'Differing Site Conditions (DSC)'\", \"'Value': 'Unknown'}\", \"{'Attribute': 'Materials (MM)'\", \"'Value': 'Yes'}\", \"{'Attribute': 'Services (SS)'\", \"'Value': 'Yes'}\", \"{'Attribute': 'Supplier Qualification (SQ)'\", \"'Value\"]\n",
      "Added process 'Collect Requirements' with dependencies: [\"[{'Input': 'requirements'\", \"'IsOutput': False\", \"'Multiplicity': '1..n'\", \"'Name': 'Inputs'}\", \"{'Input': 'project management plan'\", \"'IsOutput': False\", \"'Multiplicity': '1..1'\", \"'Name': 'Inputs'}\", \"{'Input': 'project documents\"]\n",
      "Added process 'Plan Contracting' with dependencies: [\"['Buying organization'\", \"'Selling organization'\", \"'Agreement date'\", \"'Duration of contract'\", \"'Contract price'\", \"'Type of contract'\", \"'Contract terms'\", \"'Contract changes'\", \"'Contract type'\", \"'Contract classification'\", \"'Contract contingencies'\", \"'Contract deliverables'\", \"'Contract risks'\", \"'Contract performance'\"]\n",
      "Added process 'Risk Monitoring and Control' with dependencies: [\"[{'Input': 'Risk status report'\", \"'Input_ID': '2'}\", \"{'Input': 'Risk register'\", \"'Input_ID': '3'}]\"]\n",
      "Added process 'Monitor and Control Project Work' with dependencies: [\"[{'Attribute': 'Activity List'\", \"'Guidance': 'The activity list (or WBS) is an approved tool to organize and define the project work and provide the basis for further project management planning.'}\", \"{'Attribute': 'Project Management Plan'\", \"'Guidance': 'The project management plan is an approved tool\"]\n",
      "Added process 'Receive Scope Requirements' with dependencies: ['Scope requirements']\n",
      "Added process 'Plan Human Resource Management' with dependencies: [\"[{'Attribute': 'Human Resource Plan'\", \"'Value': 'Human resource plan'}]\"]\n",
      "Added process 'Plan Risk Responses' with dependencies: [\"'risks\", 'risk management plan', 'risk register', 'risk response plans', 'identified risk responses', 'assumptions', 'plan risk management strategy', 'marketplace', 'internal audit', 'contractor', \"project team'\"]\n",
      "Added process 'Plan Procurements' with dependencies: ['Inputs to the process']\n",
      "Added process 'Plan Procurements' with dependencies: [\"[{'Name': 'Project Procurement Documentation'\", \"'Type': 'Product'}\", \"{'Name': 'Project Procurement Management Plan'\", \"'Type': 'Product'}\", \"{'Name': 'Project Management Plan'\", \"'Type': 'Product'}\", \"{'Name': 'Requirements Documents'\", \"'Type': '\"]\n",
      "Added process 'Plan Resource Management' with dependencies: [\"['Resource calendars'\", \"'Resource management plan'\", \"'Resource requirements']\"]\n",
      "Added process 'Direct and Manage Project Work' with dependencies: [\"[{'ID': 1\", \"'Description': 'Work Performance Information'}\", \"{'ID': 2\", \"'Description': 'Work Performance Data'}\", \"{'ID': 3\", \"'Description': 'Work Performance Information'}\", \"{'ID': 4\", \"'Description': 'Work Performance Data'}]\"]\n",
      "Added process 'Plan Communications Management' with dependencies: ['Project management plan', 'List of stakeholders', 'Project documents', 'Communications requirements', 'Communication methods', 'Communication technology']\n",
      "Added process 'Estimate Activity Durations' with dependencies: [\"[{'Attribute': 'Activity ID'\", \"'Value': '2.1'}\", \"{'Attribute': 'Activity Name'\", \"'Value': 'Installation of Blower'}\", \"{'Attribute': 'Time Unit'\", \"'Value': 'Days'}\", \"{'Attribute': 'Optimistic Duration'\", \"'Value': '12.\"]\n",
      "Added process 'Define Scope' with dependencies: [\"[{'Name': 'Deliverables'\", \"'Type': 'Input'\", \"'MultiSelect': False\", \"'Description': 'The required deliverables from the project to be defined.'}\", \"{'Name': 'Milestones'\", \"'Type': 'Input'\", \"'MultiSelect': False\", \"'Description': 'The major mil\"]\n",
      "Added process 'Plan Procurements' with dependencies: ['Approved Change Requests', 'Approved Project Documents', 'Contracts', 'Enterprise Environmental Factors', 'Organizational Process Assets', 'Procurement Documents', 'Requested Change Requests']\n",
      "Added process 'Plan Procurement Management' with dependencies: [\"['Deliverables'\", \"'Cost'\", \"'Deliverables cost estimate'\", \"'Project charter'\", \"'Purchasing policies'\", \"'Quality assurance plan'\", \"'Organizational process assets'\", \"'Procurement documents'\", \"'Procurement management plan'\", \"'Project management plan'\", \"'Supplier'\", \"'Cost\"]\n",
      "Added process 'Identify Risks' with dependencies: [\"[{'Activity'\", \"'Activity Name'}\", \"{'Activity'\", \"'Activity Duration'}\", \"{'Activity'\", \"'Activity Cost'}\", \"{'Activity'\", \"'Activity Budget'}\", \"{'Activity'\", \"'Activity Actual Cost'}]\"]\n",
      "Added process 'Direct and manage project integration' with dependencies: [\"[{'Name': 'Project management plan'\", \"'Type': 'Output'\", \"'Multiplier': 1\", \"'Definition': 'It is the formal\", 'approved document that defines how the project is executed', 'monitored', \"and controlled.'\", \"'Description': ''}\", \"{'Name': 'Approved change requests'\", \"'Type\"]\n",
      "Added process 'Monitor Scope' with dependencies: [\"[{'Activity List': ['Activity 20'\", \"'Activity 84'\", \"'Activity 98'\", \"'Activity 106']\", \"'Activity Attributes': {'Activity ID': 'Activity 148'\", \"'Activity Name': 'Develop Software'\", \"'Activity Type': 'P'}\", \"'\"]\n",
      "Added process 'Plan Schedule Management' with dependencies: ['Activity attributes', 'Schedule management plan', 'Resource calendars']\n",
      "Added process 'Plan Procurement Management' with dependencies: ['Procurement Management Plan']\n",
      "Added process 'Define Scope' with dependencies: [\"[{'Attribute_ID': 1\", \"'Name': 'Deliverables'}\", \"{'Attribute_ID': 2\", \"'Name': 'Project scope statement'}]\"]\n",
      "Added process 'Define Scope' with dependencies: [\"[{'Description': 'Project charter'\", \"'ID': 631\", \"'Name': 'Project charter'}\", \"{'Description': 'Product description document'\", \"'ID': 632\", \"'Name': 'Product description document'}\", \"{'Description': 'Business case'\", \"'ID': 633\"]\n",
      "Added process 'Manage Risks' with dependencies: [\"[{'Description': 'Historical information'\"]\n",
      "Added process 'Plan Procurements' with dependencies: ['Procurement documents', 'Scope baseline', 'Procurement statement of work', 'Contract statement of work', 'Procurement management plan', 'Procurement documents', 'Procurement management plan']\n",
      "Added process 'Collect Requirements' with dependencies: [\"[{'Input_Type': 'Product'\", \"'Input_Name': 'Stakeholder Register'}\", \"{'Input_Type': 'Product'\", \"'Input_Name': 'Business Vision and Business Case'}\", \"{'Input_Type': 'Product'\", \"'Input_Name': 'Project Charter'}\", \"{'Input_Type':\"]\n",
      "Added process 'Direct and Manage Project Work' with dependencies: [\"[{'Name': 'Work Performance Data'\", \"'Type': 'Output'\", \"'Multiplicity': 'M'}\", \"{'Name': 'Project Work'\", \"'Type': 'Input'\", \"'Multiplicity': 'M'}]\"]\n",
      "Added process 'Define Activities' with dependencies: [\"[{'Input Name': 'Project Management Plan'\", \"'Input Type': 'Product'}]\"]\n",
      "Added process 'Define Project Scope' with dependencies: ['Project charter']\n",
      "Added process 'Plan Scope Management' with dependencies: ['Project Scope Statement', 'Project Management Plan']\n",
      "Added process 'Develop Project Team' with dependencies: [\"[{'Name': 'Team Assignments'\", \"'Description': 'Assigns team members to the project'\", \"'Type': 'Output'}\", \"{'Name': 'Quality Metrics'\", \"'Description': 'Measures the quality of the project team'\", \"'Type': 'Output'}\", \"{'Name': 'Team Members'\", \"'\"]\n",
      "Added process 'Develop Project Charter' with dependencies: [\"[{'Description': 'Sponsor'\", \"'ID': 2}\", \"{'Description': 'Stakeholders'\", \"'ID': 3}\", \"{'Description': 'Project Manager'\", \"'ID': 10}\", \"{'Description': 'Project Team'\", \"'ID': 11}\", \"{'Description': 'Organizational\"]\n",
      "Added process 'Quality Planning' with dependencies: [\"['Planned quality metrics and targets']\"]\n",
      "Added process 'Control Integration' with dependencies: ['Work performance information', 'Key deliverables', 'Work performance information', 'Change requests', 'Work performance information', 'Work performance information']\n",
      "Added process 'Close Project or Phase' with dependencies: [\"['Project Files'\", \"'Organizational Process Assets'\", \"'Approved Change Requests'\", \"'Accepted Deliverables'\", \"'Final Reports']\"]\n",
      "Added process 'Integrate Test Strategy with Test Plan' with dependencies: [\"['Test Strategy'\", \"'Test Plan']\"]\n",
      "Added process 'Estimate Costs' with dependencies: ['[1]\\tScope Baseline']\n",
      "Added process 'Identify Stakeholders' with dependencies: [\"[{'Resource': 'Required'\", \"'Value': 'Stakeholder List'}]\"]\n",
      "Added process 'Risk Monitoring and Control' with dependencies: [\"[{\\\\'Risk Register\\\\'\", \"\\\\'Risk Report\\\\'}]\"]\n",
      "Added process 'Manage Scope' with dependencies: ['Work Breakdown Structure (WBS)', 'Scope Statement', 'WBS Dictionary']\n",
      "Added process 'Direct and Manage Project Execution' with dependencies: [\"['Activities'\", \"'Risk Register']\"]\n",
      "Added process 'Integrate Project Plan' with dependencies: ['[16', '19]']\n",
      "Added process 'Plan Risk Responses' with dependencies: [\"[{'Description': 'Responses'\", \"'Type': 'Output'}\", \"{'Description': 'Cost variance'\", \"'Type': 'Output'}]\"]\n",
      "Added process 'Identify Stakeholders' with dependencies: ['Identify Stakeholders']\n",
      "Added process 'Monitor Costs' with dependencies: ['Cost Management Plan', 'Cost Performance Index', 'Cost Variance', 'Costs']\n",
      "Added process 'Collect Requirements' with dependencies: [\"[{'Name': 'Stakeholder requirement documentation'\"]\n",
      "Added process 'Estimate Activity Resources' with dependencies: [\"[{'Key Inputs': 'Activity List'\", \"'Attribute': 'Output'}\", \"{'Key Inputs': 'Activity Attributes'\", \"'Attribute': 'Output'}]\"]\n",
      "Added process 'Manage Project Risk' with dependencies: [\"[{'Description': 'Risk register'\", \"'Type': 'Document Output'}\", \"{'Description': 'Project documents'\", \"'Type': 'Documents Input'}]\"]\n",
      "Added process 'Plan Scope Management' with dependencies: [\"[{'Type': 'T'\", \"'Description': 'Project Scope Statement'}\", \"{'Type': 'T'\", \"'Description': 'Work Performance Information'}\", \"{'Type': 'T'\", \"'Description': 'WBS'}\", \"{'Type': 'T'\", \"'Description': 'Change Request'}\", \"{'Type': 'T'\", \"'Description\"]\n",
      "Added process 'Procurement Planning' with dependencies: ['Product/Service Description', 'Request for Proposal', 'Request for Quotation', 'Invitation to Bid']\n",
      "Added process 'Risk Identification' with dependencies: ['WBS', 'OBS']\n",
      "Added process 'Execute Human Resource Activities' with dependencies: [\"[{'Outputs': []\", \"'ToolsAndTechniques': []\", \"'Inputs': ['Project Human Resource Management Plan'\", \"'Project Management Plan']}\", \"{'Outputs': ['Project Team Performance Assessment']\", \"'ToolsAndTechniques': []\", \"'Inputs': ['Project Human Resource Management Plan'\", \"'Project Management Plan']\"]\n",
      "Added process 'Direct and Manage Project Work' with dependencies: [\"['Work Performance Reports'\", \"'Work Performance Data'\", \"'Work Performance Information'\", \"'Deliverables'\", \"'Work Performance Reports'\", \"'Work Performance Data'\", \"'Work Performance Information'\", \"'Work Performance Information'\", \"'Work Performance Information']\"]\n",
      "Added process 'Develop Communication Management Plan' with dependencies: ['Communication requirements', 'Communication activities', 'Information needs', 'Output documents']\n",
      "Added process 'Make a Purchase Order' with dependencies: [\"[{'Attribute': 'Purchase Order'\", \"'Guidance': 'Enter the name of the Purchase Order'\", \"'Type': 'String'}]\"]\n",
      "Added process 'Risk Monitoring and Control' with dependencies: [\"[['Risk register']]\"]\n",
      "Added process 'Direct and Manage Project Integration' with dependencies: [\"[{'Attribute': 'Team Members'\", \"'Value': 'Jane Doe'}]\"]\n",
      "Added process 'ID: 2.3, Name: Identify Risks' with dependencies: [\"['Risk Events']\"]\n",
      "Added process 'Plan Risk Responses' with dependencies: ['Risk register', 'Risk register updates', 'Project management plan updates', 'Risk management plan']\n",
      "Added process 'Direct and Manage Project Work' with dependencies: [\"[{'Activity ID': '22.1'\", \"'Activity Name': 'Designing and building the prototype'\", \"'Activity Description': 'Develop a prototype for the new system and test it.'\", \"'Activity Type': 'Develop'}]\"]\n",
      "Added process 'Manage Stakeholder Engagement' with dependencies: [\"[{'Attribute_ID': 196\", \"'Attribute_Name': 'Stakeholder Management Plan'}\", \"{'Attribute_ID': 197\", \"'Attribute_Name': 'Stakeholder Register'}]\"]\n",
      "Added process 'Plan Programme/Project Integration' with dependencies: ['[12] Integration management plan', '[14] Project management plan', '[13] Programme/project documents', '[11] Enterprise environmental factors', '[10] Organisational process assets']\n",
      "Knowledge graph populated with processes and dependencies.\n"
     ]
    }
   ],
   "source": [
    "# Define a function to parse the 'Inputs' field, assuming it contains comma-separated values\n",
    "def parse_inputs(inputs_string):\n",
    "    return [item.strip() for item in inputs_string.split(\",\") if item.strip()]\n",
    "\n",
    "# Populate the graph with nodes and edges based on the dataset\n",
    "for idx, row in df.iterrows():\n",
    "    # Add each process as a node in the graph with default attributes if missing\n",
    "    process_id = row[\"Process_ID\"]\n",
    "    process_name = row.get(\"Process_Name\", f\"Unnamed_Process_{process_id}\")\n",
    "    knowledge_area = row[\"Knowledge_Area_Name\"]\n",
    "    process_description = row[\"Process_Description\"]\n",
    "    \n",
    "    # Add process as a node with attributes for reasoning\n",
    "    G.add_node(process_id, name=process_name, area=knowledge_area, description=process_description)\n",
    "    \n",
    "    # Parse 'Inputs' field for dependencies if it's a string\n",
    "    inputs = []\n",
    "    if isinstance(row[\"Inputs\"], str):\n",
    "        try:\n",
    "            inputs = parse_inputs(row[\"Inputs\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing Inputs for row {idx}: {e}\")\n",
    "            inputs = []\n",
    "\n",
    "    # Add edges for each input item, ensuring they are hashable\n",
    "    for input_item in inputs:\n",
    "        if isinstance(input_item, str) or isinstance(input_item, int):  # Check if input is hashable\n",
    "            G.add_edge(input_item, process_id, relationship=\"dependency\")\n",
    "        else:\n",
    "            print(f\"Skipped non-hashable input for process '{process_name}': {input_item}\")\n",
    "\n",
    "    # Debug message to confirm node and edge addition\n",
    "    print(f\"Added process '{process_name}' with dependencies: {inputs if inputs else 'None'}\")\n",
    "\n",
    "print(\"Knowledge graph populated with processes and dependencies.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasoing logic for LLama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning functions initialized.\n"
     ]
    }
   ],
   "source": [
    "# Define function to get dependencies of a given process\n",
    "def get_dependencies(process_id):\n",
    "    dependencies = list(G.predecessors(process_id))\n",
    "    print(f\"Dependencies for '{G.nodes[process_id]['name']}': {dependencies}\")\n",
    "    return dependencies\n",
    "\n",
    "# Define function to get stakeholders for a process (based on edge relationships)\n",
    "def get_stakeholders(process_id):\n",
    "    stakeholders = [node for node, attr in G.nodes(data=True) if attr.get(\"area\") == \"Stakeholder Management\"]\n",
    "    print(f\"Stakeholders for '{G.nodes[process_id]['name']}': {stakeholders}\")\n",
    "    return stakeholders\n",
    "\n",
    "# Define function to identify risk-related dependencies (mocked for simplicity)\n",
    "def get_risks(process_id):\n",
    "    risks = [node for node, attr in G.nodes(data=True) if attr.get(\"area\") == \"Risk Management\"]\n",
    "    print(f\"Risks affecting '{G.nodes[process_id]['name']}': {risks}\")\n",
    "    return risks\n",
    "\n",
    "# Debugging statements to verify function outputs\n",
    "print(\"Reasoning functions initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for Llama to query the graph\n",
    "def generate_graph_context(activity_input):\n",
    "    # Find the process ID associated with the activity input\n",
    "    process_ids = [pid for pid, data in G.nodes(data=True) if data['name'].lower() in activity_input.lower()]\n",
    "    if not process_ids:\n",
    "        print(\"No matching process found in the knowledge graph.\")\n",
    "        return \"No relevant process found in the knowledge graph.\"\n",
    "\n",
    "    process_id = process_ids[0]  # Assuming the first match\n",
    "    dependencies = get_dependencies(process_id)\n",
    "    stakeholders = get_stakeholders(process_id)\n",
    "    risks = get_risks(process_id)\n",
    "\n",
    "    # Construct context for Llama's input prompt\n",
    "    context = (\n",
    "        f\"Activity: {activity_input}\\n\"\n",
    "        f\"Dependencies: {dependencies}\\n\"\n",
    "        f\"Stakeholders: {stakeholders}\\n\"\n",
    "        f\"Risks: {risks}\\n\"\n",
    "    )\n",
    "\n",
    "    # Debug message for constructed context\n",
    "    print(f\"Constructed graph context for Llama:\\n{context}\")\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing data and model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 35 key-value pairs and 147 tensors from D:\\downloads\\Mistral modeling\\Llama-3.2-1B-Instruct-Q5_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama 3.2 1B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Llama-3.2\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 1B\n",
      "llama_model_loader: - kv   6:                            general.license str              = llama3.2\n",
      "llama_model_loader: - kv   7:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   8:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
      "llama_model_loader: - kv   9:                          llama.block_count u32              = 16\n",
      "llama_model_loader: - kv  10:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv  11:                     llama.embedding_length u32              = 2048\n",
      "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  17:                 llama.attention.key_length u32              = 64\n",
      "llama_model_loader: - kv  18:               llama.attention.value_length u32              = 64\n",
      "llama_model_loader: - kv  19:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  20:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  21:                 llama.rope.dimension_count u32              = 64\n",
      "llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  27:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  29:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  30:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  31:                      quantize.imatrix.file str              = /models_out/Llama-3.2-1B-Instruct-GGU...\n",
      "llama_model_loader: - kv  32:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  33:             quantize.imatrix.entries_count i32              = 112\n",
      "llama_model_loader: - kv  34:              quantize.imatrix.chunks_count i32              = 125\n",
      "llama_model_loader: - type  f32:   34 tensors\n",
      "llama_model_loader: - type q5_K:   96 tensors\n",
      "llama_model_loader: - type q6_K:   17 tensors\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.7999 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 2048\n",
      "llm_load_print_meta: n_layer          = 16\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 64\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 64\n",
      "llm_load_print_meta: n_embd_head_v    = 64\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 512\n",
      "llm_load_print_meta: n_embd_v_gqa     = 512\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 8192\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 131072\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = ?B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 1.24 B\n",
      "llm_load_print_meta: model size       = 861.81 MiB (5.85 BPW) \n",
      "llm_load_print_meta: general.name     = Llama 3.2 1B Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: EOM token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: EOG token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: EOG token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: ggml ctx size =    0.07 MiB\n",
      "llm_load_tensors:        CPU buffer size =   861.81 MiB\n",
      "...........................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =    16.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   16.00 MiB, K (f16):    8.00 MiB, V (f16):    8.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   254.50 MiB\n",
      "llama_new_context_with_model: graph nodes  = 518\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'Llama 3.2 1B Instruct', 'general.architecture': 'llama', 'general.type': 'model', 'llama.block_count': '16', 'general.basename': 'Llama-3.2', 'general.finetune': 'Instruct', 'general.size_label': '1B', 'general.license': 'llama3.2', 'llama.context_length': '131072', 'llama.embedding_length': '2048', 'llama.feed_forward_length': '8192', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '128009', 'general.file_type': '17', 'llama.attention.head_count_kv': '8', 'llama.rope.freq_base': '500000.000000', 'quantize.imatrix.entries_count': '112', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.attention.key_length': '64', 'llama.attention.value_length': '64', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '64', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'llama-bpe', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'quantize.imatrix.chunks_count': '125', 'quantize.imatrix.file': '/models_out/Llama-3.2-1B-Instruct-GGUF/Llama-3.2-1B-Instruct.imatrix', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"D:\\\\downloads\\\\Mistral modeling\"\n",
    "\n",
    "# Specify paths for the model and dataset\n",
    "model_path = os.path.join(base_dir, \"Llama-3.2-1B-Instruct-Q5_K_M.gguf\")\n",
    "dataset_path = os.path.join(base_dir, \"pmbok_prompt_completion_pairs.csv\")\n",
    "\n",
    "# Initialize the llama-cpp model with the specified model path\n",
    "llama = llama_cpp.Llama(model_path=model_path)\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_prompt_completion(example):\n",
    "    prompt = example[\"Prompt\"]\n",
    "    completion = example[\"Completion\"]\n",
    "    return f\"{prompt}\\n{completion}\"\n",
    "\n",
    "# Convert the dataset into prompt-completion pairs\n",
    "formatted_prompts = [prepare_prompt_completion(row) for _, row in dataset.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning Llama-3.2-1B Qunatized version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "def run_finetuning(local_model_path, dataset_path):\n",
    "    # Load the tokenizer and model from the local quantized model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "    model = AutoModelForCausalLM.from_pretrained(local_model_path)\n",
    "    \n",
    "    # Check if GPU is available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = load_dataset(\"csv\", data_files=dataset_path)\n",
    "\n",
    "    # Set training arguments tailored for a quantized model\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./fine_tuned_model\",\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        num_train_epochs=2,\n",
    "        logging_steps=10,\n",
    "        save_steps=500,\n",
    "        fp16=True if device == \"cuda\" else False,\n",
    "    )\n",
    "    \n",
    "    # Define trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "    )\n",
    "\n",
    "    # Run training\n",
    "    try:\n",
    "        trainer.train()\n",
    "        print(\"Fine-tuning completed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during fine-tuning: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Llama-3.2-1B-Instruct-Q5_K_M.gguf is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\utils\\_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 406\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/Llama-3.2-1B-Instruct-Q5_K_M.gguf/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:862\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:969\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[1;32m--> 969\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:1484\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[0;32m   1483\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1486\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:1376\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1376\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:1296\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1295\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1296\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1305\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:277\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 277\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:301\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    300\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 301\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\utils\\_http.py:454\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    446\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m     )\n\u001b[1;32m--> 454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-67344acc-0959af571ff9c34414d9872d;48f95edb-3098-4fda-b9c9-83cfefb037de)\n\nRepository Not Found for url: https://huggingface.co/Llama-3.2-1B-Instruct-Q5_K_M.gguf/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpmbok_prompt_completion_pairs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Call the function with both required arguments\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mrun_finetuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m, in \u001b[0;36mrun_finetuning\u001b[1;34m(local_model_path, dataset_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_finetuning\u001b[39m(local_model_path, dataset_path):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Load the tokenizer and model from the local quantized model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(local_model_path)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Check if GPU is available\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:857\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[0;32m    859\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:689\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[1;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[0;32m    686\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[0;32m    688\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 689\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\hub.py:426\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    427\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    431\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    437\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: Llama-3.2-1B-Instruct-Q5_K_M.gguf is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "# Set your local model path and dataset path\n",
    "local_model_path = \"Llama-3.2-1B-Instruct-Q5_K_M.gguf\"\n",
    "dataset_path = \"pmbok_prompt_completion_pairs.csv\"\n",
    "\n",
    "# Call the function with both required arguments\n",
    "run_finetuning(local_model_path, dataset_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity input and output generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph_context(activity_input):\n",
    "    # Lowercase input for case-insensitive matching\n",
    "    input_keywords = set(activity_input.lower().split())\n",
    "\n",
    "    # Find process IDs by matching keywords in `name` or `description`\n",
    "    matching_process_ids = []\n",
    "    for pid, data in G.nodes(data=True):\n",
    "        name_keywords = set(data.get(\"name\", \"\").lower().split())\n",
    "        description_keywords = set(data.get(\"description\", \"\").lower().split())\n",
    "        \n",
    "        # Check for any overlap between input keywords and node keywords\n",
    "        if input_keywords & name_keywords or input_keywords & description_keywords:\n",
    "            matching_process_ids.append(pid)\n",
    "    \n",
    "    if not matching_process_ids:\n",
    "        # Return a fallback context if no match is found\n",
    "        return \"No relevant process found in the knowledge graph.\"\n",
    "\n",
    "    # Use the first matched process ID for retrieving relevant information\n",
    "    process_id = matching_process_ids[0]\n",
    "    \n",
    "    # Retrieve and filter dependencies, stakeholders, and risks (keep only string values)\n",
    "    dependencies = [dep for dep in get_dependencies(process_id) if isinstance(dep, str)]\n",
    "    stakeholders = [stake for stake in get_stakeholders(process_id) if isinstance(stake, str)]\n",
    "    risks = [risk for risk in get_risks(process_id) if isinstance(risk, str)]\n",
    "\n",
    "    # Construct the context summary for Llama's prompt\n",
    "    context = (\n",
    "        f\"Activity: {activity_input}\\n\"\n",
    "        f\"Dependencies: {dependencies}\\n\"\n",
    "        f\"Stakeholders: {stakeholders}\\n\"\n",
    "        f\"Risks: {risks}\\n\"\n",
    "    )\n",
    "    \n",
    "    return context  # Only return the constructed context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies for 'Direct and Manage Project Work': [\"[['Project Management Plan'\", \"'Assignments'\", \"'Agreements'\", \"'Project Documents'\", \"'Issues'\", \"'Organizational Process Assets']]\", '[7] Communications Management Plan', '[8] Organizational Process Assets', '[9] Project Documents', \"['Work performance data'\", \"'Work performance information'\", \"'Team performance reports']\"]\n",
      "Stakeholders for 'Direct and Manage Project Work': [49, 108, 24, 119, 9]\n",
      "Risks affecting 'Direct and Manage Project Work': [85, 5, 62, 59, 139, 76, 107, 10, 140, 118, 17, 57, 30, 1141, 1031]\n",
      "Final Prompt to Llama:\n",
      " Activity: Provide a detailed 7-day mobile app development plan. Outline each day’s tasks, key\n",
      "milestones, and expected deliverables.\n",
      "\n",
      "Dependencies: [\"[['Project Management Plan'\", \"'Assignments'\", \"'Agreements'\", \"'Project Documents'\", \"'Issues'\", \"'Organizational Process Assets']]\", '[7] Communications Management Plan', '[8] Organizational Process Assets', '[9] Project Documents', \"['Work performance data'\", \"'Work performance information'\", \"'Team performance reports']\"]\n",
      "Stakeholders: []\n",
      "Risks: []\n",
      "\n",
      "\n",
      "Activity: Provide a detailed 7-day mobile app development plan. Outline each day’s tasks, key\n",
      "milestones, and expected deliverables.\n",
      "\n",
      "\n",
      "Please generate a practical project plan specific to the activity, including:\n",
      "- Timeline with Key Milestones\n",
      "- Resource Requirements\n",
      "- Dependencies\n",
      "- Brief Risk Assessment with mitigation suggestions\n",
      "- Stakeholder Communication Needs (if relevant)\n",
      "\n",
      "Provide actionable, specific information directly related to the activity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 190 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    4083.57 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   321 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   17664.94 ms /   322 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:  Here is the detailed plan:\n",
      "\n",
      "\n",
      "**Day 1: Project Management Plan and Assignments**\n",
      "\n",
      "* **Project Management Plan**: Define project scope, objectives, timelines, budget, resources, and deliverables.\n",
      "* **Assignments**: Identify team members, their roles, responsibilities, and expectations.\n",
      "* **Agreements**: Establish communication channels, issue resolution processes, and conflict resolution procedures.\n",
      "* **Project Documents**: Create a project charter, scope statement, and change management plan.\n",
      "* **Work performance data**: Collect initial data on team performance, including task completion rates and feedback.\n",
      "\n",
      "Expected Deliverables:\n",
      "\n",
      "* Project Management Plan document\n",
      "* Assignments document\n",
      "* Agreements document\n",
      "* Project Charter\n",
      "* Scope Statement\n",
      "* Change Management Plan\n",
      "\n",
      "**Day 2: Organizational Process Assets**\n",
      "\n",
      "* **Organizational Process Assets**: Identify and document existing processes, procedures, and standards.\n",
      "* **Project Documents**: Update project documents to reflect organizational process assets.\n",
      "* **Work performance information**: Collect data on team performance, including task completion rates and feedback.\n",
      "\n",
      "Expected Deliverables:\n",
      "\n",
      "* Organizational Process Assets document\n",
      "* Updated Project Documents\n",
      "* Work Performance Information report\n",
      "\n",
      "**Day 3: Mobile App Development Plan**\n",
      "\n",
      "* **Mobile App Development Plan**: Define project scope, objectives, timelines, budget, resources, and deliverables.\n",
      "* **Dependencies**: Identify dependencies on third-party services, APIs, and tools.\n",
      "* **Brief Risk Assessment**: Identify potential risks and develop mitigation strategies.\n",
      "\n",
      "Expected Deliverables:\n",
      "\n",
      "* Mobile App Development Plan document\n",
      "* Dependencies list\n",
      "* Brief Risk Assessment report\n",
      "\n",
      "**Day 4: Design and Prot\n",
      "Warning: The response is missing sections: ['Objective and Scope', 'Timeline with Key Milestones', 'Resource Requirements']\n"
     ]
    }
   ],
   "source": [
    "def generate_response_with_graph(activity_input):\n",
    "    # Retrieve relevant context from the knowledge graph based on the input\n",
    "    graph_context = generate_graph_context(activity_input)\n",
    "\n",
    "    # Tailored prompt to ensure relevance to `activity_input`\n",
    "    prompt = (\n",
    "        f\"{graph_context}\\n\\n\"\n",
    "        f\"Activity: {activity_input}\\n\\n\"\n",
    "        \"Please generate a practical project plan specific to the activity, including:\\n\"\n",
    "        \"- Timeline with Key Milestones\\n\"\n",
    "        \"- Resource Requirements\\n\"\n",
    "        \"- Dependencies\\n\"\n",
    "        \"- Brief Risk Assessment with mitigation suggestions\\n\"\n",
    "        \"- Stakeholder Communication Needs (if relevant)\\n\\n\"\n",
    "        \"Provide actionable, specific information directly related to the activity.\"\n",
    "    )\n",
    "    \n",
    "    # Print prompt for debugging\n",
    "    print(\"Final Prompt to Llama:\\n\", prompt)\n",
    "\n",
    "    # Generate response with adjusted parameters for relevance and specificity\n",
    "    response = llama(\n",
    "        prompt,\n",
    "        max_tokens=1900,  # Adjusted for focused output within 900 tokens\n",
    "        temperature=0,  # Reduced temperature for coherent, concise output\n",
    "        top_p=0.1,\n",
    "        presence_penalty=0.8,  # Encourage thorough coverage of all sections\n",
    "        frequency_penalty=0.3   # Minimize repetitive sections\n",
    "    )\n",
    "\n",
    "    # Extract and print the model response text\n",
    "    output_text = response[\"choices\"][0][\"text\"]\n",
    "    print(\"Model Response:\", output_text)\n",
    "    \n",
    "    # Validate the response includes the key sections\n",
    "    required_sections = [\n",
    "        \"Objective and Scope\",\n",
    "        \"Timeline with Key Milestones\",\n",
    "        \"Resource Requirements\",\n",
    "        \"Dependencies\",\n",
    "        \"Risk Assessment\",\n",
    "    ]\n",
    "    \n",
    "    # Identify missing sections for review\n",
    "    missing_sections = [section for section in required_sections if section not in output_text]\n",
    "    if missing_sections:\n",
    "        print(\"Warning: The response is missing sections:\", missing_sections)\n",
    "    \n",
    "    return output_text\n",
    "\n",
    "# Run the updated function using dynamic `activity_input`\n",
    "Fine_tuned_Response = generate_response_with_graph(activity_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Relevant Information from Llama’s Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_entities_from_output(output_text):\n",
    "    \"\"\"\n",
    "    Extract tasks, dependencies, risks, and stakeholders from Llama's output.\n",
    "    This function uses regex to identify key phrases for simplicity.\n",
    "    \"\"\"\n",
    "    tasks = re.findall(r\"Tasks?: (.+?)(?:\\n|$)\", output_text)\n",
    "    dependencies = re.findall(r\"Dependencies?: (.+?)(?:\\n|$)\", output_text)\n",
    "    risks = re.findall(r\"Risks?: (.+?)(?:\\n|$)\", output_text)\n",
    "    stakeholders = re.findall(r\"Stakeholders?: (.+?)(?:\\n|$)\", output_text)\n",
    "\n",
    "    # Debug output for extracted entities\n",
    "    print(\"Extracted Tasks:\", tasks)\n",
    "    print(\"Extracted Dependencies:\", dependencies)\n",
    "    print(\"Extracted Risks:\", risks)\n",
    "    print(\"Extracted Stakeholders:\", stakeholders)\n",
    "    \n",
    "    return tasks, dependencies, risks, stakeholders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Ponderation Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define keyword sets for relevance scoring\n",
    "task_keywords = {\"task\", \"milestone\", \"deliverable\", \"complete\"}\n",
    "dependency_keywords = {\"dependency\", \"requirement\", \"before\", \"after\"}\n",
    "risk_keywords = {\"risk\", \"issue\", \"challenge\", \"mitigation\"}\n",
    "stakeholder_keywords = {\"stakeholder\", \"team\", \"manager\", \"client\", \"involved\"}\n",
    "\n",
    "def score_entity(entity, keywords):\n",
    "    \"\"\"\n",
    "    Assign a relevance score based on the presence of keywords.\n",
    "    Higher scores for entities with multiple relevant keywords.\n",
    "    \"\"\"\n",
    "    words = set(entity.lower().split())\n",
    "    score = sum(1 for word in words if word in keywords)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ponderate_entities(entities, keywords):\n",
    "    \"\"\"\n",
    "    Filter and rank entities based on contextual relevance using keyword scoring.\n",
    "    \"\"\"\n",
    "    scored_entities = [(entity, score_entity(entity, keywords)) for entity in entities]\n",
    "    # Filter out entities with a score of 0 (no relevance)\n",
    "    scored_entities = [(entity, score) for entity, score in scored_entities if score > 0]\n",
    "    # Sort by score in descending order\n",
    "    ranked_entities = sorted(scored_entities, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Debug output for scored entities\n",
    "    print(\"Scored and Ranked Entities:\", ranked_entities)\n",
    "    \n",
    "    # Return only the entity names, not the scores, for final output\n",
    "    return [entity for entity, score in ranked_entities]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Graph expansion if applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_graph_with_llama_output(output_text):\n",
    "    # Extract entities from Llama’s output\n",
    "    tasks, dependencies, risks, stakeholders = extract_entities_from_output(output_text)\n",
    "    \n",
    "    # Ponderate each category with contextual scoring\n",
    "    tasks = ponderate_entities(tasks, task_keywords)\n",
    "    dependencies = ponderate_entities(dependencies, dependency_keywords)\n",
    "    risks = ponderate_entities(risks, risk_keywords)\n",
    "    stakeholders = ponderate_entities(stakeholders, stakeholder_keywords)\n",
    "    \n",
    "    # Add tasks as new nodes\n",
    "    for task in tasks:\n",
    "        G.add_node(task, type=\"task\")\n",
    "        print(f\"Added task node: {task}\")\n",
    "    \n",
    "    # Add dependencies as edges between tasks if applicable\n",
    "    for dependency in dependencies:\n",
    "        task_links = dependency.split(\" and \")\n",
    "        if len(task_links) == 2:\n",
    "            G.add_edge(task_links[0].strip(), task_links[1].strip(), relationship=\"dependency\")\n",
    "            print(f\"Added dependency edge: {task_links[0].strip()} -> {task_links[1].strip()}\")\n",
    "    \n",
    "    # Add risks and link them to tasks\n",
    "    for risk in risks:\n",
    "        G.add_node(risk, type=\"risk\")\n",
    "        for task in tasks:\n",
    "            G.add_edge(risk, task, relationship=\"risk_impact\")\n",
    "            print(f\"Added risk impact edge: {risk} -> {task}\")\n",
    "    \n",
    "    # Add stakeholders and link them to tasks\n",
    "    for stakeholder in stakeholders:\n",
    "        G.add_node(stakeholder, type=\"stakeholder\")\n",
    "        for task in tasks:\n",
    "            G.add_edge(stakeholder, task, relationship=\"involvement\")\n",
    "            print(f\"Added stakeholder involvement edge: {stakeholder} -> {task}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Generate a response and expand the graph with new information\n",
    "activity_input = \"Identify additional tasks and risks for the mobile app project lifecycle\"\n",
    "response_text = generate_response_with_graph(activity_input)  # Assuming this generates a response\n",
    "\n",
    "# Expand the graph using Llama's output\n",
    "expand_graph_with_llama_output(response_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refinig output with a more perfomrant models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "# Loading API\n",
    "with open(\"pmkey.txt\", \"r\") as file:\n",
    "    api_key = file.read().strip()\n",
    "os.environ[\"GROQ_API_KEY\"] = api_key\n",
    "\n",
    "# Initialize Groq client\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "# Define a function to refine the already-generated model output using Groq API\n",
    "def refine_with_groq(model_output):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Refine the following project plan to be more grounded in reality and well-structured:\\n\\n{model_output}\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Send request to Groq API\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"llama3-8b-8192\" \n",
    "    )\n",
    "    \n",
    "    # Retrieve and print the refined output\n",
    "    refined_output = chat_completion.choices[0].message.content\n",
    "    print(\"Refined Output from Groq API:\", refined_output)\n",
    "    return refined_output\n",
    "\n",
    "# Call refine_with_groq to refine this stored response\n",
    "refined_output = refine_with_groq(Fine_tuned_Response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human evaluation and other Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores: [{'rouge-1': {'r': 0.5333333333333333, 'p': 0.034334763948497854, 'f': 0.06451612789574664}, 'rouge-2': {'r': 0.0625, 'p': 0.002347417840375587, 'f': 0.004524886180053751}, 'rouge-l': {'r': 0.5333333333333333, 'p': 0.034334763948497854, 'f': 0.06451612789574664}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abder\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.5321035981178284\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "reference_text = \"\"\"\n",
    "Day 1: Define project scope, objectives, and team roles. \n",
    "Day 2: Requirements gathering and stakeholder analysis...\n",
    "\"\"\"  \n",
    "\n",
    "# ROUGE Score\n",
    "rouge = Rouge()\n",
    "rouge_scores = rouge.get_scores(refined_output, reference_text)\n",
    "print(\"ROUGE Scores:\", rouge_scores)\n",
    "\n",
    "# Cosine Similarity\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "output_embedding = model.encode(refined_output, convert_to_tensor=True)\n",
    "reference_embedding = model.encode(reference_text, convert_to_tensor=True)\n",
    "cosine_similarity = util.pytorch_cos_sim(output_embedding, reference_embedding)\n",
    "print(\"Cosine Similarity:\", cosine_similarity.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
